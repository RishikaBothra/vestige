{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf92f8d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../sql/data/State_wise_Total_Updates.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Load data\u001b[39;00m\n\u001b[32m      5\u001b[39m centres = pd.read_excel(\u001b[33m\"\u001b[39m\u001b[33m../sql/data/Aadhar.xlsx\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m updates = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../sql/data/State_wise_Total_Updates.xlsx\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Standardize column names\u001b[39;00m\n\u001b[32m      9\u001b[39m centres = centres.rename(columns={\n\u001b[32m     10\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mState\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mstate\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     11\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mNo. of centres\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mcentres\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     12\u001b[39m })\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/vestige/.venv/lib/python3.13/site-packages/pandas/io/excel/_base.py:495\u001b[39m, in \u001b[36mread_excel\u001b[39m\u001b[34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[39m\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[32m    494\u001b[39m     should_close = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m495\u001b[39m     io = \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine != io.engine:\n\u001b[32m    502\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    503\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mEngine should not be specified when passing \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    504\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    505\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/vestige/.venv/lib/python3.13/site-packages/pandas/io/excel/_base.py:1550\u001b[39m, in \u001b[36mExcelFile.__init__\u001b[39m\u001b[34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[39m\n\u001b[32m   1548\u001b[39m     ext = \u001b[33m\"\u001b[39m\u001b[33mxls\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1549\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1550\u001b[39m     ext = \u001b[43minspect_excel_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1551\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\n\u001b[32m   1552\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1553\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1554\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1555\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mExcel file format cannot be determined, you must specify \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1556\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33man engine manually.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1557\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/vestige/.venv/lib/python3.13/site-packages/pandas/io/excel/_base.py:1402\u001b[39m, in \u001b[36minspect_excel_format\u001b[39m\u001b[34m(content_or_path, storage_options)\u001b[39m\n\u001b[32m   1399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[32m   1400\u001b[39m     content_or_path = BytesIO(content_or_path)\n\u001b[32m-> \u001b[39m\u001b[32m1402\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1403\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m   1404\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[32m   1405\u001b[39m     stream = handle.handle\n\u001b[32m   1406\u001b[39m     stream.seek(\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/vestige/.venv/lib/python3.13/site-packages/pandas/io/common.py:882\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    873\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(\n\u001b[32m    874\u001b[39m             handle,\n\u001b[32m    875\u001b[39m             ioargs.mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m    878\u001b[39m             newline=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    879\u001b[39m         )\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m882\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    883\u001b[39m     handles.append(handle)\n\u001b[32m    885\u001b[39m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '../sql/data/State_wise_Total_Updates.xlsx'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "demo = pd.read_parquet(\"../sql/data/data_cache/demographic_clean.parquet\")\n",
    "bio = pd.read_parquet(\"../sql/data/data_cache/biometric_clean.parquet\")\n",
    "\n",
    "centres = pd.read_csv(\"../sql/data/Aadhar.csv\")\n",
    "population = pd.read_csv(\"../sql/data/clean_population.csv\")\n",
    "\n",
    "\n",
    "centres = centres.rename(columns={\n",
    "    \"State\": \"state\",\n",
    "    \"No. of centres\": \"centres\"\n",
    "})\n",
    "\n",
    "population = population.rename(columns={\n",
    "    \"state_name\": \"state\",\n",
    "    \"population\": \"population\"\n",
    "})\n",
    "\n",
    "\n",
    "updates = pd.concat([demo, bio]).groupby(\"state\").size().reset_index(name=\"total_updates\")\n",
    "\n",
    "\n",
    "centres[\"centres\"] = pd.to_numeric(centres[\"centres\"], errors=\"coerce\")\n",
    "updates[\"total_updates\"] = pd.to_numeric(updates[\"total_updates\"], errors=\"coerce\")\n",
    "population[\"population\"] = pd.to_numeric(population[\"population\"], errors=\"coerce\")\n",
    "\n",
    "\n",
    "def normalize_state(s):\n",
    "    return (\n",
    "        s.astype(str)\n",
    "        .str.strip()\n",
    "        .str.lower()\n",
    "        .str.replace(\"&\", \"and\", regex=False)\n",
    "        .str.replace(r\"\\s+\", \" \", regex=True)\n",
    "        .str.replace(\" islands\", \"\", regex=False)\n",
    "        .str.replace(\"dadra nagar haveli\", \"dadra and nagar haveli\", regex=False)\n",
    "        .str.replace(\"arunanchal pradesh\", \"arunachal pradesh\", regex=False)\n",
    "    )\n",
    "\n",
    "centres[\"state\"] = normalize_state(centres[\"state\"])\n",
    "updates[\"state\"] = normalize_state(updates[\"state\"])\n",
    "population[\"state\"] = normalize_state(population[\"state\"])\n",
    "\n",
    "\n",
    "df = centres.merge(updates, on=\"state\", how=\"inner\")\n",
    "df = df.merge(population, on=\"state\", how=\"inner\")\n",
    "\n",
    "\n",
    "df = df.dropna(subset=[\"centres\", \"total_updates\", \"population\"])\n",
    "df = df[df[\"centres\"] > 0]\n",
    "df = df[df[\"population\"] > 0]\n",
    "\n",
    "\n",
    "df[\"updates_per_centre\"] = df[\"total_updates\"] / df[\"centres\"]\n",
    "df[\"centres_per_100k_population\"] = (df[\"centres\"] / df[\"population\"]) * 100000\n",
    "\n",
    "\n",
    "df[\"state_display\"] = df[\"state\"].str.title()\n",
    "df[\"state_display\"] = df[\"state_display\"].str.replace(\n",
    "    \"Dadra And Nagar Haveli And Daman And Diu\",\n",
    "    \"Dadra & NH and D&D\",\n",
    "    regex=False\n",
    ")\n",
    "\n",
    "\n",
    "df_updates = df.sort_values(\"updates_per_centre\", ascending=False)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "ax.barh(\n",
    "    df_updates[\"state_display\"],\n",
    "    df_updates[\"updates_per_centre\"],\n",
    "    edgecolor=\"white\",\n",
    "    linewidth=0.5,\n",
    "    color=\"#2E86AB\"\n",
    ")\n",
    "\n",
    "\n",
    "ax.set_xlabel(\"Average Updates per Aadhaar Centre\", fontsize=12, fontweight=\"bold\")\n",
    "ax.set_title(\n",
    "    \"Aadhaar Updates per Centre by State/UT\",\n",
    "    fontsize=14,\n",
    "    fontweight=\"bold\",\n",
    "    pad=20\n",
    ")\n",
    "\n",
    "\n",
    "ax.grid(axis=\"x\", linestyle=\"--\", alpha=0.3)\n",
    "ax.set_axisbelow(True)\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "\n",
    "for i, value in enumerate(df_updates[\"updates_per_centre\"]):\n",
    "    ax.text(value, i, f\"{value:.0f}\", va=\"center\", fontsize=9)\n",
    "\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "df_centres = df.sort_values(\"centres_per_100k_population\", ascending=False)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "ax.barh(\n",
    "    df_centres[\"state_display\"],\n",
    "    df_centres[\"centres_per_100k_population\"],\n",
    "    edgecolor=\"white\",\n",
    "    linewidth=0.5,\n",
    "    color=\"#A23B72\"\n",
    ")\n",
    "\n",
    "\n",
    "ax.set_xlabel(\"Centres per 100,000 Population\", fontsize=12, fontweight=\"bold\")\n",
    "ax.set_title(\n",
    "    \"Aadhaar Centre Infrastructure Density by State/UT\",\n",
    "    fontsize=14,\n",
    "    fontweight=\"bold\",\n",
    "    pad=20\n",
    ")\n",
    "\n",
    "\n",
    "ax.grid(axis=\"x\", linestyle=\"--\", alpha=0.3)\n",
    "ax.set_axisbelow(True)\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "\n",
    "for i, value in enumerate(df_centres[\"centres_per_100k_population\"]):\n",
    "    ax.text(value, i, f\"{value:.1f}\", va=\"center\", fontsize=9)\n",
    "\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"\\n=== UPDATES PER CENTRE STATISTICS ===\")\n",
    "print(f\"Mean: {df['updates_per_centre'].mean():.2f}\")\n",
    "print(f\"Median: {df['updates_per_centre'].median():.2f}\")\n",
    "print(f\"Min: {df['updates_per_centre'].min():.2f}\")\n",
    "print(f\"Max: {df['updates_per_centre'].max():.2f}\")\n",
    "\n",
    "print(\"\\n=== CENTRES PER 100,000 POPULATION STATISTICS ===\")\n",
    "print(f\"Mean: {df['centres_per_100k_population'].mean():.2f}\")\n",
    "print(f\"Median: {df['centres_per_100k_population'].median():.2f}\")\n",
    "print(f\"Min: {df['centres_per_100k_population'].min():.2f}\")\n",
    "print(f\"Max: {df['centres_per_100k_population'].max():.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vestige",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
